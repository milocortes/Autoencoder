{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " En esta rutina utilizaremos Autoencoders para reducir la dimensión de nuestros datos. Como usaremos Colab, usaremos las siguientes instrucciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall tf-nightly-gpu-2.0-preview\n",
    "!git clone https://github.com/milocortes/Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# scientific python stack\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML/DL\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tkl\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "print('Tensorflow:{}'.format(tf.__version__))\n",
    "print('Keras:{}'.format(tfk.__version__))\n",
    "print('Tf-prob:{}'.format(tfp.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el directorio para poder cargar nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /content/Autoencoder/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('muni_2015_ine_inegi.csv')\n",
    "\n",
    "# Eliminamos la primer columna\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos la matriz de diseño:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "train_index,test_index = train_test_split(df.index,test_size=0.2)\n",
    "x = np.vstack(np.array(df).tolist()).astype(np.float32)\n",
    "#y = df['logp'].values.reshape(-1,1).astype(np.float32)\n",
    "x_train,x_test = x[train_index],x[test_index]\n",
    "#y_train,y_test = y[train_index],y[test_index]\n",
    "#print(x.shape,y.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducimos a 2 dimensiones con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = PCA(2)\n",
    "x_pca = model.fit_transform(x_test)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x_pca[:,0],x_pca[:,1],s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construimos un PCA con un linear autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfkl = tf.keras.layers\n",
    "\n",
    "latent_dim=2\n",
    "input_dim = x.shape[-1]\n",
    "encoder = tf.keras.Sequential([\n",
    "        tfkl.InputLayer(input_shape=[input_dim]),\n",
    "        tfkl.Dense(latent_dim,activation=None)])\n",
    "decoder = tf.keras.Sequential([\n",
    "        tfkl.InputLayer(input_shape=[latent_dim]),\n",
    "        tfkl.Dense(input_dim,activation=None)])\n",
    "\n",
    "ae = tfk.Model(inputs=encoder.inputs,outputs=decoder(encoder.outputs)) \n",
    "ae.compile('adam',loss='mse')\n",
    "ae.summary()\n",
    "ae.fit(x_train,x_train,batch_size=64,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodificar, decodificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = encoder.predict(x_test)\n",
    "recon_x = decoder.predict(z)\n",
    "print(np.abs(recon_x[0]-x[0]))\n",
    "print(np.linalg.norm(recon_x[0]-x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos el espacio latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(z[:,0],z[:,1],s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Espacio latente $z$ de dos dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "latent_dim=2\n",
    "input_dim = x.shape[-1]\n",
    "\n",
    "## Definimos el encoder\n",
    "encoder = tf.keras.Sequential([\n",
    "        tfkl.InputLayer(input_shape=[input_dim]),\n",
    "        tfkl.Dense(150, activation='relu', kernel_initializer='normal'),\n",
    "        tfkl.Dense(100, activation='relu', kernel_initializer='normal'),\n",
    "        tfkl.Dense(50, activation='relu', kernel_initializer='normal'),\n",
    "        tfkl.Dense(10, activation='relu', kernel_initializer='normal'),\n",
    "        tfkl.Dense(latent_dim,activation=None)])\n",
    "## Encodificamos\n",
    "z = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Visualizamos el espacio latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(z[:,0],z[:,1],s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Espacio latente $z$ de tres dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfkl = tf.keras.layers\n",
    "\n",
    "## Definimos la dimensión\n",
    "latent_dim=3\n",
    "input_dim = x.shape[-1]\n",
    "\n",
    "## Definimos el encoder\n",
    "\n",
    "encoder = tf.keras.Sequential([\n",
    "        tfkl.InputLayer(input_shape=[input_dim]),\n",
    "        tfkl.Dense(150, activation=tf.nn.leaky_relu, kernel_initializer='normal'),\n",
    "        tfkl.Dense(100, activation=tf.nn.leaky_relu, kernel_initializer='normal'),\n",
    "        tfkl.Dense(100, activation='relu', kernel_initializer='normal'),\n",
    "        #tfkl.Dense(50, activation='relu', kernel_initializer='normal'),\n",
    "        #tfkl.Dense(10, activation='relu', kernel_initializer='normal'),\n",
    "        #tfkl.Dense(latent_dim,activation=None)])\n",
    "## Encodificamos\n",
    "z = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizamos el espacio latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "x_vals=z[:,0]\n",
    "y_vals=z[:,1]\n",
    "z_vals=z[:,2]\n",
    "\n",
    "ax.scatter(x_vals, y_vals, z_vals)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
